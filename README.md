Claro! Aqui est√° a tradu√ß√£o para o ingl√™s:

---

# üíª Machine Learning with Stacking: Lead Classification and Medical Cost Prediction

This project showcases the application of **Machine Learning techniques using the Stacking model** in two distinct scenarios:

- **Marketing Lead Classification** to predict the conversion of potential customers.
- **Medical Cost Regression** to estimate expenses based on demographic and behavioral features.

Both solutions were developed with a focus on **data exploration**, **structured preprocessing**, and **robust model evaluation**.

---

## üìÅ Data Structure

### Marketing Leads (`leads_cleaned.csv`)

- Problem: Binary classification (Converted or Not Converted).
- Features: Demographics, acquisition channels, interaction history, etc.
- Target: `Converted`

### Medical Costs (`healthcosts_cleaned.csv`)

- Problem: Continuous value regression (medical cost in dollars).
- Features: Age, sex, BMI, number of children, smoking status, region, etc.
- Target: `medical charges`

---

## ‚öôÔ∏è Technologies Used

- **Language:** Python 3
- **Visualization Libraries:** `Seaborn`, `Plotly`, `Matplotlib`
- **Data Manipulation:** `Pandas`, `NumPy`
- **Machine Learning:** `Scikit-learn`
- **Packaging and Environment:** `pipenv`, `joblib` (for saving/preprocessors)

---

## üß™ Project Steps

### 1. Exploratory Data Analysis (EDA)

- Data visualization using `Seaborn` and `Plotly`
- Understanding the structure of the datasets

### 2. Data Preparation

- Splitting into numerical and categorical features
- Applying a saved `preprocessor` using `joblib`
- Splitting data into train and test sets (80/20)

### 3. Model Training

#### üîµ Classification (Leads)

- Base Algorithms:
  - `SGDClassifier`
  - `SVC`
  - `DecisionTreeClassifier`
- Meta-model:
  - `LogisticRegression`
- Strategy:
  - `StackingClassifier` (Vanilla)

#### üî¥ Regression (Medical Costs)

- Base Algorithms:
  - `LinearRegression`
  - `ElasticNet`
  - `DecisionTreeRegressor`
- Meta-model:
  - `HuberRegressor`
- Strategy:
  - `StackingRegressor` (Vanilla)

---

## üìä Model Evaluation

### Classification

- **Evaluated Metrics:**
  - Accuracy
  - Precision
  - Recall
  - F1-Score
- **Visualization:**
  - Interactive confusion matrix (`Plotly`)
- **Additional Analysis:**
  - Average feature importance from base algorithms

### Regression

- **Evaluated Metrics:**
  - RMSE (Root Mean Squared Error)
  - R¬≤ (Coefficient of Determination)
- **Visualization:**
  - Predictor variable importance

---

## üîç Model Explainability

- Individual predictions from base algorithms and final Stacking model (Classification)
- Direct comparison of results from each estimator

---

## üì¶ How to Run

1. **Install dependencies:**

```bash
pip install -r requirements.txt
```

2. **Activate the virtual environment:**

```bash
pipenv shell
```

3. **Run the notebooks or scripts:**
   - `stacking_leads.ipynb` (or the respective `.py` script)
   - `stacking_costs.ipynb` (or the respective `.py` script)

---

## üß† Key Learnings

This project reinforces the importance of **feature engineering**, **curation of base models** in ensemble architectures, and **interpretation of results**, promoting robust and explainable models for real-world problems.

---

Claro! Aqui est√° a tradu√ß√£o completa para o espanhol:

---

# üíª Machine Learning con Stacking: Clasificaci√≥n de Leads y Predicci√≥n de Costos M√©dicos

Este proyecto presenta la aplicaci√≥n de **t√©cnicas de Aprendizaje Autom√°tico utilizando el modelo Stacking** en dos escenarios distintos:

- **Clasificaci√≥n de Leads de Marketing** para predecir la conversi√≥n de clientes potenciales.
- **Regresi√≥n de Costos M√©dicos** para estimar gastos en funci√≥n de caracter√≠sticas demogr√°ficas y de comportamiento.

Ambas soluciones fueron desarrolladas con enfoque en la **exploraci√≥n de datos**, **preprocesamiento estructurado** y **evaluaci√≥n robusta de los modelos**.

---

## üìÅ Estructura de los Datos

### Leads de Marketing (`leads_cleaned.csv`)

- Problema: Clasificaci√≥n binaria (Convertido o No Convertido).
- Caracter√≠sticas: Datos demogr√°ficos, canales de adquisici√≥n, historial de interacciones, etc.
- Variable objetivo: `Converted`

### Costos M√©dicos (`healthcosts_cleaned.csv`)

- Problema: Regresi√≥n de valor continuo (costo m√©dico en d√≥lares).
- Caracter√≠sticas: Edad, sexo, IMC, n√∫mero de hijos, h√°bito de fumar, regi√≥n, etc.
- Variable objetivo: `medical charges`

---

## ‚öôÔ∏è Tecnolog√≠as Utilizadas

- **Lenguaje:** Python 3
- **Librer√≠as de Visualizaci√≥n:** `Seaborn`, `Plotly`, `Matplotlib`
- **Manipulaci√≥n de Datos:** `Pandas`, `NumPy`
- **Aprendizaje Autom√°tico:** `Scikit-learn`
- **Empaquetado y Entorno:** `pipenv`, `joblib` (para guardar/preprocesadores)

---

## üß™ Etapas del Proyecto

### 1. An√°lisis Exploratorio de Datos (EDA)

- Visualizaci√≥n de datos usando `Seaborn` y `Plotly`
- Comprensi√≥n de la estructura de los conjuntos de datos

### 2. Preparaci√≥n de los Datos

- Separaci√≥n en caracter√≠sticas num√©ricas y categ√≥ricas
- Aplicaci√≥n de un `preprocessor` guardado con `joblib`
- Divisi√≥n de los datos en conjuntos de entrenamiento y prueba (80/20)

### 3. Entrenamiento de Modelos

#### üîµ Clasificaci√≥n (Leads)

- Algoritmos Base:
  - `SGDClassifier`
  - `SVC`
  - `DecisionTreeClassifier`
- Meta-modelo:
  - `LogisticRegression`
- Estrategia:
  - `StackingClassifier` (Vanilla)

#### üî¥ Regresi√≥n (Costos M√©dicos)

- Algoritmos Base:
  - `LinearRegression`
  - `ElasticNet`
  - `DecisionTreeRegressor`
- Meta-modelo:
  - `HuberRegressor`
- Estrategia:
  - `StackingRegressor` (Vanilla)

---

## üìä Evaluaci√≥n de Modelos

### Clasificaci√≥n

- **M√©tricas Evaluadas:**
  - Precisi√≥n (Accuracy)
  - Precisi√≥n Positiva (Precision)
  - Sensibilidad (Recall)
  - F1-Score
- **Visualizaci√≥n:**
  - Matriz de confusi√≥n interactiva (`Plotly`)
- **An√°lisis Adicional:**
  - Importancia promedio de las caracter√≠sticas en los modelos base

### Regresi√≥n

- **M√©tricas Evaluadas:**
  - RMSE (Error Cuadr√°tico Medio)
  - R¬≤ (Coeficiente de Determinaci√≥n)
- **Visualizaci√≥n:**
  - Importancia de las variables predictoras

---

## üîç Explicabilidad del Modelo

- Predicciones individuales de los algoritmos base y del modelo final de Stacking (Clasificaci√≥n)
- Comparaci√≥n directa de los resultados de cada estimador

---

## üì¶ C√≥mo Ejecutar

1. **Instalar dependencias:**

```bash
pip install -r requirements.txt
```

2. **Activar el entorno virtual:**

```bash
pipenv shell
```

3. **Ejecutar los notebooks o scripts:**
   - `stacking_leads.ipynb` (o el script `.py` correspondiente)
   - `stacking_costs.ipynb` (o el script `.py` correspondiente)

---

## üß† Aprendizajes Clave

Este proyecto refuerza la importancia de la **ingenier√≠a de caracter√≠sticas**, la **selecci√≥n cuidadosa de modelos base** en arquitecturas de ensamble, y la **interpretaci√≥n de resultados**, promoviendo modelos robustos y explicables para problemas del mundo real.

---

# üíª Machine Learning com Stacking: Classifica√ß√£o de Leads e Previs√£o de Custos M√©dicos

Este projeto apresenta a aplica√ß√£o de t√©cnicas de **Aprendizado de M√°quina com o modelo Stacking** em dois contextos distintos:

- **Classifica√ß√£o de Leads de Marketing** para prever a convers√£o de clientes potenciais.
- **Regress√£o de Custos M√©dicos** para estimar despesas com base em caracter√≠sticas demogr√°ficas e comportamentais.

Ambas as solu√ß√µes foram desenvolvidas com foco em **explora√ß√£o de dados**, **preprocessamento estruturado** e **avalia√ß√£o robusta dos modelos**.

---

## üìÅ Estrutura dos Dados

### Leads de Marketing (`leads_cleaned.csv`)

- Problema: Classifica√ß√£o bin√°ria (Convertido ou N√£o Convertido).
- Atributos: Dados demogr√°ficos, canais de aquisi√ß√£o, hist√≥rico de intera√ß√µes, etc.
- Target: `Converted`

### Custos M√©dicos (`healthcosts_cleaned.csv`)

- Problema: Regress√£o de valor cont√≠nuo (custo m√©dico em d√≥lares).
- Atributos: Idade, sexo, IMC, n√∫mero de filhos, tabagismo, regi√£o, etc.
- Target: `medical charges`

---

## ‚öôÔ∏è Tecnologias Utilizadas

- **Linguagem:** Python 3
- **Bibliotecas de Visualiza√ß√£o:** `Seaborn`, `Plotly`, `Matplotlib`
- **Manipula√ß√£o de Dados:** `Pandas`, `NumPy`
- **Machine Learning:** `Scikit-learn`
- **Empacotamento e Ambiente:** `pipenv`, `joblib` (para salvar/preprocessadores)

---

## üß™ Etapas do Projeto

### 1. An√°lise Explorat√≥ria (EDA)

- Visualiza√ß√£o de dados com `Seaborn` e `Plotly`
- Compreens√£o da estrutura dos datasets

### 2. Prepara√ß√£o dos Dados

- Separa√ß√£o em features num√©ricas e categ√≥ricas
- Aplica√ß√£o de um `preprocessor` salvo com `joblib`
- Divis√£o dos dados em treino e teste (80/20)

### 3. Treinamento dos Modelos

#### üîµ Classifica√ß√£o (Leads)

- Algoritmos Base:
  - `SGDClassifier`
  - `SVC`
  - `DecisionTreeClassifier`
- Meta-modelo:
  - `LogisticRegression`
- Estrat√©gia:
  - `StackingClassifier` (Vanilla)

#### üî¥ Regress√£o (Custos M√©dicos)

- Algoritmos Base:
  - `LinearRegression`
  - `ElasticNet`
  - `DecisionTreeRegressor`
- Meta-modelo:
  - `HuberRegressor`
- Estrat√©gia:
  - `StackingRegressor` (Vanilla)

---

## üìä Avalia√ß√£o dos Modelos

### Classifica√ß√£o

- **M√©tricas Avaliadas:**
  - Acur√°cia
  - Precis√£o
  - Recall
  - F1-Score
- **Visualiza√ß√£o:**
  - Matriz de confus√£o interativa (`Plotly`)
- **An√°lise Adicional:**
  - Import√¢ncia m√©dia das features dos algoritmos base

### Regress√£o

- **M√©tricas Avaliadas:**
  - RMSE (Root Mean Squared Error)
  - R¬≤ (Coeficiente de Determina√ß√£o)
- **Visualiza√ß√£o:**
  - Import√¢ncia das vari√°veis preditoras

---

## üîç Explicabilidade dos Modelos

- Predi√ß√µes individuais dos algoritmos base e da predi√ß√£o final do modelo de Stacking (Classifica√ß√£o)
- Compara√ß√£o direta dos resultados de cada estimador

---

## üì¶ Como Executar

1. **Instale as depend√™ncias:**

```bash
pip install -r requirements.txt
```

2. **Ative o ambiente virtual:**

```bash
pipenv shell
```

3. **Execute os notebooks ou scripts:**
   - `stacking_leads.ipynb` (ou o respectivo script `.py`)
   - `stacking_costs.ipynb` (ou o respectivo script `.py`)

---

## üß† Aprendizados

Este projeto refor√ßa a import√¢ncia da **engenharia de atributos**, da **curadoria dos modelos base** em arquiteturas de ensemble, e da **interpreta√ß√£o de resultados**, promovendo modelos robustos e interpret√°veis para problemas do mundo real.
